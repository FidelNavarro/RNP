{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_21\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_36 (Dense)             (None, 8)                 24        \n",
      "_________________________________________________________________\n",
      "dense_37 (Dense)             (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 33\n",
      "Trainable params: 33\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6999 - accuracy: 0.5000\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6972 - accuracy: 0.5000\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.6923 - accuracy: 0.5000\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6855 - accuracy: 0.5000\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6770 - accuracy: 0.5000\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6672 - accuracy: 0.7500\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6564 - accuracy: 0.7500\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.6451 - accuracy: 0.7500\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 996us/step - loss: 0.6348 - accuracy: 0.7500\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.6245 - accuracy: 0.7500\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6141 - accuracy: 0.7500\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6051 - accuracy: 0.7500\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5949 - accuracy: 0.7500\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5849 - accuracy: 0.7500\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 981us/step - loss: 0.5740 - accuracy: 0.7500\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.5628 - accuracy: 0.7500\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.5516 - accuracy: 0.7500\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.5372 - accuracy: 0.7500\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.5225 - accuracy: 1.0000\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5053 - accuracy: 1.0000\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.4888 - accuracy: 1.0000\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.4712 - accuracy: 1.0000\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.4545 - accuracy: 1.0000\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.4395 - accuracy: 1.0000\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.4184 - accuracy: 1.0000\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3993 - accuracy: 1.0000\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.3804 - accuracy: 1.0000\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.3604 - accuracy: 1.0000\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.3407 - accuracy: 1.0000\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.3218 - accuracy: 1.0000\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.3039 - accuracy: 1.0000\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.2859 - accuracy: 1.0000\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2669 - accuracy: 1.0000\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.2487 - accuracy: 1.0000\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.2322 - accuracy: 1.0000\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.2168 - accuracy: 1.0000\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.2020 - accuracy: 1.0000\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.1878 - accuracy: 1.0000\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.1749 - accuracy: 1.0000\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.1628 - accuracy: 1.0000\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.1520 - accuracy: 1.0000\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.1417 - accuracy: 1.0000\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.1321 - accuracy: 1.0000\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 996us/step - loss: 0.1243 - accuracy: 1.0000\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.1156 - accuracy: 1.0000\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.1088 - accuracy: 1.0000\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.1019 - accuracy: 1.0000\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.0960 - accuracy: 1.0000\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.0904 - accuracy: 1.0000\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.0854 - accuracy: 1.0000\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.0808 - accuracy: 1.0000\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.0761 - accuracy: 1.0000\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.0725 - accuracy: 1.0000\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.0692 - accuracy: 1.0000\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.0659 - accuracy: 1.0000\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.0628 - accuracy: 1.0000\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.0598 - accuracy: 1.0000\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.0569 - accuracy: 1.0000\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.0543 - accuracy: 1.0000\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.0522 - accuracy: 1.0000\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.0502 - accuracy: 1.0000\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0483 - accuracy: 1.0000\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.0466 - accuracy: 1.0000\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.0450 - accuracy: 1.0000\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.0432 - accuracy: 1.0000\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.0417 - accuracy: 1.0000\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.0406 - accuracy: 1.0000\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.0393 - accuracy: 1.0000\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0381 - accuracy: 1.0000\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.0371 - accuracy: 1.0000\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 996us/step - loss: 0.0360 - accuracy: 1.0000\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.0350 - accuracy: 1.0000\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.0341 - accuracy: 1.0000\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.0331 - accuracy: 1.0000\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0322 - accuracy: 1.0000\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.0314 - accuracy: 1.0000\n",
      "Epoch 77/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 0s/step - loss: 0.0307 - accuracy: 1.0000\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.0301 - accuracy: 1.0000\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.0293 - accuracy: 1.0000\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0286 - accuracy: 1.0000\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.0280 - accuracy: 1.0000\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.0274 - accuracy: 1.0000\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.0269 - accuracy: 1.0000\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.0264 - accuracy: 1.0000\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.0259 - accuracy: 1.0000\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.0254 - accuracy: 1.0000\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.0249 - accuracy: 1.0000\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.0245 - accuracy: 1.0000\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.0241 - accuracy: 1.0000\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 996us/step - loss: 0.0237 - accuracy: 1.0000\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.0232 - accuracy: 1.0000\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.0229 - accuracy: 1.0000\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.0226 - accuracy: 1.0000\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.0222 - accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.0218 - accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0215 - accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.0212 - accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.0209 - accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.0206 - accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 996us/step - loss: 0.0203 - accuracy: 1.0000\n",
      "Evaluating on training set...\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x0000018792D9F0D0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "loss=0.0200, accuracy: 100.0000%\n",
      "Maximum Loss : 0.6999\n",
      "\n",
      "Minimum Loss : 0.0203\n",
      "\n",
      "Loss difference : 0.6796\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense\n",
    "\n",
    "# the four different states of the XOR gate\n",
    "training_data = np.array([[0,0],[0,1],[1,0],[1,1]], \"float32\")\n",
    "\n",
    "# the four expected results in the same order\n",
    "target_data = np.array([[0],[1],[1],[0]], \"float32\")\n",
    "\n",
    "# Hyperparameters\n",
    "training_epochs = 100 # Total number of training epochs\n",
    "learning_rate = 0.1 # The learning rate\n",
    "momentum = 0.9\n",
    "\n",
    "# create a model\n",
    "def create_model():\n",
    "    model = tf.keras.Sequential()\n",
    "    # Hidden layer\n",
    "    model.add(tf.keras.layers.Dense(8, input_dim=2,activation='relu'))\n",
    "    # Output layer\n",
    "    model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "    # Compile a model\n",
    "    model.compile(loss='binary_crossentropy', \n",
    "                  optimizer=tf.keras.optimizers.SGD(learning_rate, momentum),\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model = create_model()\n",
    "model.summary()\n",
    "\n",
    "results = model.fit(\n",
    "    training_data, target_data,\n",
    "    epochs= training_epochs,\n",
    "#    validation_data = (X_test, y_test.T),\n",
    "    verbose = 1\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "print(\"Evaluating on training set...\")\n",
    "(loss, accuracy) = model.evaluate(training_data, target_data, verbose=0)\n",
    "print(\"loss={:.4f}, accuracy: {:.4f}%\".format(loss,accuracy * 100))\n",
    "\n",
    "#print(\"Evaluating on testing set...\")\n",
    "#(loss, accuracy) = model.evaluate(X_test, y_test.T, verbose=0)\n",
    "#print(\"loss={:.4f}, accuracy: {:.4f}%\".format(loss,accuracy * 100))\n",
    "\n",
    "\n",
    "# summarize history for accuracy\n",
    "plt.plot(results.history['accuracy'])\n",
    "#plt.plot(results.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "#plt.legend(['train', 'test'])\n",
    "\n",
    "\n",
    "# summarize history for loss\n",
    "plt.plot(results.history['loss'])\n",
    "#plt.plot(results.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "#plt.legend(['train', 'test'])\n",
    "\n",
    "max_loss = np.max(results.history['loss'])\n",
    "min_loss = np.min(results.history['loss'])\n",
    "print(\"Maximum Loss : {:.4f}\".format(max_loss))\n",
    "print(\"\")\n",
    "print(\"Minimum Loss : {:.4f}\".format(min_loss))\n",
    "print(\"\")\n",
    "print(\"Loss difference : {:.4f}\".format((max_loss - min_loss)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
